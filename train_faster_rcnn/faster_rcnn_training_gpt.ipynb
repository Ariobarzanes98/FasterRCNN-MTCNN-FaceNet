{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d83ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '../data/VOC2012_images'\n",
    "csv_path = '../data/test_Pascal_custom.csv'\n",
    "\n",
    "image_filenames = os.listdir(image_dir)\n",
    "print(f\"Total images: {len(image_filenames)}\")\n",
    "\n",
    "targets = pd.read_csv(csv_path)\n",
    "targets.head()  # Display first few rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2067e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PascalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, phase):\n",
    "        self.phase = phase\n",
    "        self.targets = pd.read_csv(f'../data/{phase}_Pascal_custom.csv')\n",
    "        self.imgs = self.targets['filename']\n",
    "        self.label_map = {'person': 1, 'dog': 2}  # Extend as needed\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join('../data/VOC2012_images', self.imgs[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = F.to_tensor(img)\n",
    "\n",
    "        box_list = self.targets[self.targets['filename'] == self.imgs[idx]]\n",
    "        idx_lbls = box_list[['class']].values\n",
    "        box_list = box_list[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "\n",
    "        boxes = torch.tensor(box_list, dtype=torch.float32)\n",
    "        labels = torch.tensor([self.label_map.get(x[0], 0) for x in idx_lbls], dtype=torch.int64)\n",
    "        if labels.dim() == 0:\n",
    "            labels = labels.unsqueeze(0)\n",
    "\n",
    "        return img, {'boxes': boxes, 'labels': labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = PascalDataset('train')\n",
    "test_dataset = PascalDataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e756ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Test a batch\n",
    "images, targets = next(iter(train_loader))\n",
    "print(f\"Batch size: {len(images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained model\n",
    "num_classes = 3  # Adjust based on dataset\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed428d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, targets in train_dataloader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        total_loss += losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_one_epoch(model, optimizer, train_loader)\n",
    "    print(f\"Epoch [{epoch}]: LR {lr_scheduler.get_last_lr()} Loss {loss:.4f}\")\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1743e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    os.makedirs(\"../data/output_images\", exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for cnt, (images, targets) in enumerate(test_dataloader):\n",
    "            images = [img.to(device) for img in images]\n",
    "            out = model(images)[0]\n",
    "\n",
    "            img = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "            gt_boxes = targets[0]['boxes'].cpu().numpy()\n",
    "            pred_boxes = out['boxes'].cpu().numpy()\n",
    "            pred_scores = out['scores'].cpu().numpy()\n",
    "            pred_labels = out['labels'].cpu().numpy()\n",
    "\n",
    "            fig, ax = plt.subplots(1)\n",
    "            ax.imshow(img)\n",
    "\n",
    "            # Draw Ground Truth\n",
    "            for box in gt_boxes:\n",
    "                rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='g', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "            # Draw Predictions\n",
    "            for i, box in enumerate(pred_boxes):\n",
    "                if pred_scores[i] > 0.7:\n",
    "                    rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.text(box[0], box[1] - 10, f\"{pred_labels[i]} ({pred_scores[i]:.2f})\", color='m')\n",
    "\n",
    "            fig.savefig(f\"../data/output_images/{cnt}.png\", dpi=90, bbox_inches='tight')\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38150afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301198f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/detection_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py (facet)",
   "language": "python",
   "name": "facet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
